# Project Implementation Description
1. The *Confluent Datagen - Clickstreaming* data source continuously populates the web-application-clickstream Kafka Topic with web application traffic data.
2. The Confluent HTTP Sink (*clickhouse-webclicks*) writes the topic data to the Clickhouse *default.webclicks* table.
3. Clickhouse Views are generated by dbt automation. The dbt automation includes tests for expected values (ex: non-null values, percentages between 0 and 100 inclusive, etc.)
4. A Preset dataset is created for each of the Clickhouse Views.
5. A Preset Dashboard is created from each of the datasets.
# Screenshots
## Confluent Cloud
### Environment View
![../img/confluent-environment.png](../img/confluent-environment.png)
### Kafka Topic
![../img/confluent-Kafka-topic.png](../img/confluent-Kafka-topic.png)
## Clickhouse
### Service View
![../img/clickhouse-00-service.png](../img/clickhouse-00-service.png)
### Data Sink Results View
![../img/clickhouse-01-webclicks-kafka-import.png](../img/clickhouse-01-webclicks-kafka-import.png)
### dbt-Generated Model Views
![../img/clickhouse-02-views.png](../img/clickhouse-02-views.png)
## Preset
### Webclicks Analytics Dashboard
![../img/preset-dashboard.png](../img/preset-dashboard.png)